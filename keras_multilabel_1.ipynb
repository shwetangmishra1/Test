{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_multilabel_1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shwetangmishra1/Test/blob/master/keras_multilabel_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hYillQWZMYAQ",
        "colab_type": "code",
        "outputId": "9630150b-300f-4456-f34d-45600ad001f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#Imports\n",
        "import tensorflow as tf\n",
        "from imutils import paths\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.optimizers import Adam\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from pyimagesearch.smallervggnet import SmallerVGGNet\n",
        "import matplotlib.pyplot as plt\n",
        "from imutils import paths\n",
        "import numpy as np\n",
        "import argparse\n",
        "import random\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "# import the necessary packages\n",
        "#from keras.preprocessing.image import img_to_array\n",
        "from keras.models import load_model\n",
        "import imutils"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rZfZnyzUNZvX",
        "colab_type": "code",
        "outputId": "7439037e-60da-4647-97e3-42d848b2cbee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# Check for GPU \n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  #raise SystemError('GPU device not found')\n",
        "  print(\"No gpu device\")\n",
        "else:\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TaBgFVP4T_Th",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "######## downloading dataset from drive to colab########\n",
        "!pip install -U -q PyDrive\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7IetQMApUHGt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 1. Authentinon_ receipte and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lFtCbbuBUR1Y",
        "colab_type": "code",
        "outputId": "00edf4eb-8d4e-44c6-e676-8e2351d0aee1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# choose a local (colab) directory to store the data.\n",
        "# local_download_path = os.path.expanduser('~/content')\n",
        "# print(local_download_path)\n",
        "# try:\n",
        "#   os.makedirs(local_download_path)\n",
        "# except: pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x6scKBIhUMDk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# 2. Auto-iterate using the query syntax\n",
        "#    https://developers.google.com/drive/v2/web/search-parameters\n",
        "# file_list = drive.ListFile(\n",
        "#     {'q': \"'1omj-ZSMAR5JIctEQZ4aG-Y4f5i7DYK48' in parents\"}).GetList()\n",
        "\n",
        "# print(file_list)\n",
        "\n",
        "#file_id = '1omj-ZSMAR5JIctEQZ4aG-Y4f5i7DYK48' # URL id. for fashion dataset\n",
        "file_id = '1PNvLdRyYGfwUxnSOF7xy7ztc8-gArGPh' # url id for stainless steel datset\n",
        "file_id_tsv_file = '1PNvLdRyYGfwUxnSOF7xy7ztc8-gArGPh'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "downloaded.GetContentFile('stainless_steel_final_dataset.zip')\n",
        "#downloaded.GetContentFile('stainless_labels5.tsv.3split.tsv')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vCi71szRUs0A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for f in file_list:\n",
        "#   # 3. Create & download by id.\n",
        "#   print('title: %s, id: %s' % (f['title'], f['id']))\n",
        "#   fname = os.path.join(local_download_path, f['title'])\n",
        "#   print('downloading to {}'.format(fname))\n",
        "#   f_ = drive.CreateFile({'id': f['id']})\n",
        "#   f_.GetContentFile(fname)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xtn6f08DYP4P",
        "colab_type": "code",
        "outputId": "1147ca31-d46e-4a22-ad06-e655cf5421ab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "# Unzip the zipped data\n",
        "!sudo apt-get install unzip"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 8 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "egTNkyqOahWv",
        "colab_type": "code",
        "outputId": "ee51858e-3c09-40c0-a0ea-93d91b96cad9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "# unzip the dataset\n",
        "# path : content/dataset.zip\n",
        "#!unzip /content/dataset.zip -d /content/dataset\n",
        "!unzip /content/stainless_steel_final_dataset.zip -d /content"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/stainless_steel_final_dataset.zip\n",
            "replace /content/stainless_steel_final_dataset/stainless_labels5.tsv.3split.tsv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x0yaJOm_Nce5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# import the necessary packages\n",
        "from keras.models import Sequential\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers.core import Activation\n",
        "from keras.layers.core import Flatten\n",
        "from keras.layers.core import Dropout\n",
        "from keras.layers.core import Dense\n",
        "from keras import backend as K\n",
        "\n",
        "class SmallerVGGNet:\n",
        "\t@staticmethod\n",
        "\tdef build(width, height, depth, classes, finalAct=\"softmax\"):\n",
        "\t\t# initialize the model along with the input shape to be\n",
        "\t\t# \"channels last\" and the channels dimension itself\n",
        "\t\tmodel = Sequential()\n",
        "\t\tinputShape = (height, width, depth)\n",
        "\t\tchanDim = -1\n",
        "\n",
        "\t\t# if we are using \"channels first\", update the input shape\n",
        "\t\t# and channels dimension\n",
        "\t\tif K.image_data_format() == \"channels_first\":\n",
        "\t\t\tinputShape = (depth, height, width)\n",
        "\t\t\tchanDim = 1\n",
        "\n",
        "\t\t# CONV => RELU => POOL\n",
        "\t\tmodel.add(Conv2D(32, (3, 3), padding=\"same\",\n",
        "\t\t\tinput_shape=inputShape))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(64, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# (CONV => RELU) * 2 => POOL\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(Conv2D(128, (3, 3), padding=\"same\"))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\t\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\t\tmodel.add(Dropout(0.25))\n",
        "\n",
        "\t\t# first (and only) set of FC => RELU layers\n",
        "\t\tmodel.add(Flatten())\n",
        "\t\tmodel.add(Dense(1024))\n",
        "\t\tmodel.add(Activation(\"relu\"))\n",
        "\t\tmodel.add(BatchNormalization())\n",
        "\t\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t\t# softmax classifier\n",
        "\t\tmodel.add(Dense(classes))\n",
        "\t\tmodel.add(Activation(finalAct))\n",
        "\n",
        "\t\t# return the constructed network architecture\n",
        "\t\treturn model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TtSM004hOtCS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Set all the necessary paths.\n",
        "#dataset_path = \"/content/dataset/dataset/\"\n",
        "dataset_path = \"/content/stainless_steel_final_dataset/stainless_images5\"\n",
        "#output_model_path = \"/content/fashion.model\"\n",
        "output_model_path = \"/content/ssteel.model\"\n",
        "#labelbin = \"/content/mlb.pickle\"\n",
        "plot = \"/content/plot_ssteel.png\"\n",
        "labelbin = \"/content/steel_mlb.pickle\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-TGANMumPLbY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the number of epochs to train for, initial learning rate,\n",
        "# batch size, and image dimensions\n",
        "EPOCHS = 75\n",
        "INIT_LR = 1e-3\n",
        "BS = 32\n",
        "IMAGE_DIMS = (256, 256, 3)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aZtzb03WPPYI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4jvXdxPYPnDi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# grab the image paths and randomly shuffle them\n",
        "# print(\"[INFO] loading images...\")\n",
        "# imagePaths = sorted(list(paths.list_images(dataset_path)))\n",
        "# print(len(imagePaths))\n",
        "# assert(len(imagePaths)== 2165)\n",
        "# random.seed(42)\n",
        "# random.shuffle(imagePaths)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wgtBLDvvQyP7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loop over the input images\n",
        "#for imagePath in imagePaths:\n",
        "\t# load the image, pre-process it, and store it in the data list\n",
        "# \timage = cv2.imread(imagePath)\n",
        "# \timage = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "# \timage = img_to_array(image)\n",
        "# \tdata.append(image)\n",
        "\n",
        "\t# extract set of class labels from the image path and update the\n",
        "\t# labels list\n",
        "# \tl = label = imagePath.split(os.path.sep)[-2].split(\"_\")\n",
        "# \tlabels.append(l)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7GubyHRTFCh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hbzu22z3R4wT",
        "colab_type": "code",
        "outputId": "11d0859a-4f32-4f48-c6c1-236745788c66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "cell_type": "code",
      "source": [
        "# getting all the labels\n",
        "df = pd.read_csv('/content/stainless_steel_final_dataset/stainless_labels5.tsv.3split.tsv',sep = '\\t')\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ImageName</th>\n",
              "      <th>Labels</th>\n",
              "      <th>dataset_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0006-5519593-20161101-7341-E-Dreyfus-Avenue-12...</td>\n",
              "      <td>stainless steel fridge,stainless steel oven,st...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0006-5516609-20161026-10026-W-Potter-Drive-22.jpg</td>\n",
              "      <td>NaN</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0006-5521796-20161106-7516-E-Woodshire-Cove-1.jpg</td>\n",
              "      <td>stainless steel Dishwasher</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0006-5507235-20161006-1725-W-Burnside-Trail-7.jpg</td>\n",
              "      <td>stainless steel fridge,stainless steel Chimney</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0006-5480519-20160805-2255-E-Squaw-Peak-Drive-...</td>\n",
              "      <td>stainless steel Dishwasher</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           ImageName  \\\n",
              "0  0006-5519593-20161101-7341-E-Dreyfus-Avenue-12...   \n",
              "1  0006-5516609-20161026-10026-W-Potter-Drive-22.jpg   \n",
              "2  0006-5521796-20161106-7516-E-Woodshire-Cove-1.jpg   \n",
              "3  0006-5507235-20161006-1725-W-Burnside-Trail-7.jpg   \n",
              "4  0006-5480519-20160805-2255-E-Squaw-Peak-Drive-...   \n",
              "\n",
              "                                              Labels dataset_type  \n",
              "0  stainless steel fridge,stainless steel oven,st...        train  \n",
              "1                                                NaN        train  \n",
              "2                         stainless steel Dishwasher        train  \n",
              "3     stainless steel fridge,stainless steel Chimney        train  \n",
              "4                         stainless steel Dishwasher        train  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "metadata": {
        "id": "NGjQwB7sTecQ",
        "colab_type": "code",
        "outputId": "63ef8350-d117-490e-c82e-45c7f635fbb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        }
      },
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10527 entries, 0 to 10526\n",
            "Data columns (total 3 columns):\n",
            "ImageName       10527 non-null object\n",
            "Labels          5759 non-null object\n",
            "dataset_type    10527 non-null object\n",
            "dtypes: object(3)\n",
            "memory usage: 246.8+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pC89_qLAb4S1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# df = df[pd.notnull(df['Labels'])]\n",
        "# df.info()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QEVRg8BlcK_T",
        "colab_type": "code",
        "outputId": "8dd24489-9ca9-4a64-f6bd-f2a107b99f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['ImageName', 'Labels', 'dataset_type'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "y0LwyKDodFh7",
        "colab_type": "code",
        "outputId": "ed4a838b-b050-474a-f495-1bf46b1f373c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "imagenames = list(df.iloc[:,0])[:3000]\n",
        "len(imagenames)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "evN_dWiOdSau",
        "colab_type": "code",
        "outputId": "c3e990e7-32eb-4551-fdb0-932e8f5535f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "labels = list(df.iloc[:,1])[:3000]\n",
        "len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "MZoXdV4IdbQT",
        "colab_type": "code",
        "outputId": "c23977f8-8f37-4b90-b59b-20b9a8db4961",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "labels[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stainless steel fridge,stainless steel oven,stainless steel Microwave',\n",
              " nan,\n",
              " 'stainless steel Dishwasher',\n",
              " 'stainless steel fridge,stainless steel Chimney',\n",
              " 'stainless steel Dishwasher']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "metadata": {
        "id": "HuoT5bJFVLBg",
        "colab_type": "code",
        "outputId": "03f8e848-47c4-468f-e9c7-570f0d061549",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# TO-DO : get all image paths and shuffle them\n",
        "imagePaths = [os.path.join(\"/content/stainless_steel_final_dataset/stainless_images5/\",imgname) for imgname in imagenames]\n",
        "print(len(imagePaths))\n",
        "assert os.path.exists(imagePaths[0])\n",
        "# print(len(imagePaths))\n",
        "# #assert(len(imagePaths)== 2165)\n",
        "# random.seed(42)\n",
        "# random.shuffle(imagePaths)\n",
        "# print(len(imagePaths))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5r_flm5xeebQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# TO-DO : get all labels for images from the data file \n",
        "for imagePath in imagePaths:\n",
        "  image = cv2.imread(imagePath)\n",
        "  image = cv2.resize(image, (IMAGE_DIMS[1], IMAGE_DIMS[0]))\n",
        "  image = img_to_array(image)\n",
        "  data.append(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zVbk0gLHfOhD",
        "colab_type": "code",
        "outputId": "38c0ff93-29a3-4a05-85a3-ecae2f9f2814",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(len(data))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SYJPBckQd8Lw",
        "colab_type": "code",
        "outputId": "434986ba-814c-45f4-e00e-9cb1f7920703",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        }
      },
      "cell_type": "code",
      "source": [
        "labels[:5]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stainless steel fridge,stainless steel oven,stainless steel Microwave',\n",
              " nan,\n",
              " 'stainless steel Dishwasher',\n",
              " 'stainless steel fridge,stainless steel Chimney',\n",
              " 'stainless steel Dishwasher']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "metadata": {
        "id": "Kq8sA_uyCAws",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NSWeYEqXCScb",
        "colab_type": "code",
        "outputId": "adaddc40-2f10-4c82-a13a-f29576fa02cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "metadata": {
        "id": "zF34dbuWfd-K",
        "colab_type": "code",
        "outputId": "9335e26b-7c1f-4370-eb97-ea20f9e9928e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "cell_type": "code",
      "source": [
        "labels1 = []\n",
        "for val in labels:\n",
        "  #print(val)\n",
        "  temp = []\n",
        "  if str(val) == 'nan':\n",
        "    labels1.append(temp)\n",
        "    continue\n",
        "  values = val.split(',')\n",
        "  for v in values:\n",
        "    #print(v)\n",
        "    tval = v.replace(\" \",\"_\")\n",
        "    temp.append(tval)\n",
        "  labels1.append(temp)  \n",
        "print(len(labels1))  \n",
        "print(labels1[:5])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3000\n",
            "[['stainless_steel_fridge', 'stainless_steel_oven', 'stainless_steel_Microwave'], [], ['stainless_steel_Dishwasher'], ['stainless_steel_fridge', 'stainless_steel_Chimney'], ['stainless_steel_Dishwasher']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ASI1XOqCm5f2",
        "colab_type": "code",
        "outputId": "b8f2bec5-937e-4b9d-9328-f382f38cdfbe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "labels1[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stainless_steel_fridge', 'stainless_steel_oven', 'stainless_steel_Microwave']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "Gt4DyE6cWxpR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#df.index\n",
        "#df.iloc[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0qujMnAU0v_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# for image_path in imagePaths[:2]:\n",
        "#   image_name = image_path.split('/')[-1]\n",
        "#   #print(image_name)\n",
        "#   label = df[image_name][Labels]\n",
        "#   print(label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gjfL_095gYpK",
        "colab_type": "code",
        "outputId": "936ad9a8-76a8-43c2-8f57-da496130d46b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"No of image files {} and no of labels {}\".format(len(data),len(labels1)))\n",
        "#print(data[0],labels1[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No of image files 3000 and no of labels 3000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BbP4ufUZREQK",
        "colab_type": "code",
        "outputId": "436a4db7-acbc-49a8-f4f5-5124f6ade215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# scale the raw pixel intensities to the range [0, 1]\n",
        "data = np.array(data, dtype=\"float\") / 255.0\n",
        "labels1 = np.array(labels1)\n",
        "print(\"[INFO] data matrix: {} images ({:.2f}MB)\".format(len(imagePaths), data.nbytes / (1024 * 1000.0)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] data matrix: 3000 images (4608.00MB)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ktXU303cRUwF",
        "colab_type": "code",
        "outputId": "3675cdd6-9d64-4f00-9644-89b2067b8029",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# binarize the labels using scikit-learn's special multi-label\n",
        "# binarizer implementation\n",
        "print(\"[INFO] class labels:\")\n",
        "mlb = MultiLabelBinarizer()\n",
        "labels1 = mlb.fit_transform(labels1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] class labels:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "liOblrhfqODp",
        "colab_type": "code",
        "outputId": "17f75092-c852-4571-9a03-69ee7282b68d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "print(mlb.classes_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['stainless_steel_Chimney' 'stainless_steel_Dishwasher'\n",
            " 'stainless_steel_Microwave' 'stainless_steel_Sink'\n",
            " 'stainless_steel_Stove' 'stainless_steel_fridge' 'stainless_steel_oven']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g8RenhpLRqrz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loop over each of the possible class labels and show them\n",
        "# for (i, label) in enumerate(mlb.classes_):\n",
        "# \tprint(\"{}. {}\".format(i + 1, labels1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M7BfiyYmpVDX",
        "colab_type": "code",
        "outputId": "67e361ce-f64d-425e-93f7-228ed123516a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "labels1[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "metadata": {
        "id": "N6ZsQWfHUAqk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# partition the data into training and testing splits using 80% of\n",
        "# the data for training and the remaining 20% for testing\n",
        "(trainX, testX, trainY, testY) = train_test_split(data,labels1, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hsSqnJBZUa9R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# construct the image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=25, width_shift_range=0.1,height_shift_range=0.1, shear_range=0.2, zoom_range=0.2,horizontal_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "AquQvYimUf89",
        "colab_type": "code",
        "outputId": "fe95bab0-f2c3-4b74-f2e4-e8224c590cf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# initialize the model using a sigmoid activation as the final layer\n",
        "# in the network so we can perform multi-label classification\n",
        "print(\"[INFO] compiling model...\")\n",
        "model = SmallerVGGNet.build(width=IMAGE_DIMS[1], height=IMAGE_DIMS[0],depth=IMAGE_DIMS[2], classes=len(mlb.classes_),finalAct=\"sigmoid\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] compiling model...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5G_bGJF0UoJv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# initialize the optimizer (SGD is sufficient)\n",
        "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VkCn9llkUq7u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# compile the model using binary cross-entropy rather than\n",
        "# categorical cross-entropy -- this may seem counterintuitive for\n",
        "# multi-label classification, but keep in mind that the goal here\n",
        "# is to treat each output label as an independent Bernoulli\n",
        "# distribution\n",
        "model.compile(loss=\"binary_crossentropy\", optimizer=opt,metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wyUnD7Q2UvKL",
        "colab_type": "code",
        "outputId": "89a96595-1a02-4992-87bc-ba97f2918cb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2763
        }
      },
      "cell_type": "code",
      "source": [
        "# train the network\n",
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n",
            "Epoch 1/75\n",
            "263/263 [==============================] - 32s 121ms/step - loss: 0.5924 - acc: 0.7370 - val_loss: 0.6586 - val_acc: 0.7076\n",
            "Epoch 2/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.4880 - acc: 0.8028 - val_loss: 2.1043 - val_acc: 0.6820\n",
            "Epoch 3/75\n",
            "263/263 [==============================] - 26s 97ms/step - loss: 0.4670 - acc: 0.8095 - val_loss: 0.4803 - val_acc: 0.7945\n",
            "Epoch 4/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.4516 - acc: 0.8162 - val_loss: 0.4548 - val_acc: 0.8097\n",
            "Epoch 5/75\n",
            "263/263 [==============================] - 25s 96ms/step - loss: 0.4361 - acc: 0.8199 - val_loss: 0.5399 - val_acc: 0.8175\n",
            "Epoch 6/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.4251 - acc: 0.8253 - val_loss: 0.7294 - val_acc: 0.7024\n",
            "Epoch 7/75\n",
            "263/263 [==============================] - 26s 97ms/step - loss: 0.4200 - acc: 0.8274 - val_loss: 0.4204 - val_acc: 0.8295\n",
            "Epoch 8/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.4160 - acc: 0.8307 - val_loss: 0.4732 - val_acc: 0.7987\n",
            "Epoch 9/75\n",
            "263/263 [==============================] - 25s 96ms/step - loss: 0.4176 - acc: 0.8314 - val_loss: 0.5111 - val_acc: 0.8072\n",
            "Epoch 10/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.4291 - acc: 0.8274 - val_loss: 0.5080 - val_acc: 0.7824\n",
            "Epoch 11/75\n",
            "263/263 [==============================] - 26s 97ms/step - loss: 0.4145 - acc: 0.8313 - val_loss: 0.4119 - val_acc: 0.8279\n",
            "Epoch 12/75\n",
            "263/263 [==============================] - 26s 98ms/step - loss: 0.4001 - acc: 0.8377 - val_loss: 0.3980 - val_acc: 0.8398\n",
            "Epoch 13/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3954 - acc: 0.8383 - val_loss: 0.4042 - val_acc: 0.8390\n",
            "Epoch 14/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.4032 - acc: 0.8365 - val_loss: 0.4592 - val_acc: 0.8350\n",
            "Epoch 15/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3892 - acc: 0.8422 - val_loss: 0.4143 - val_acc: 0.8245\n",
            "Epoch 16/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3890 - acc: 0.8419 - val_loss: 0.3809 - val_acc: 0.8472\n",
            "Epoch 17/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3818 - acc: 0.8450 - val_loss: 0.4194 - val_acc: 0.8304\n",
            "Epoch 18/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.3774 - acc: 0.8482 - val_loss: 0.7171 - val_acc: 0.7896\n",
            "Epoch 19/75\n",
            "263/263 [==============================] - 26s 97ms/step - loss: 0.3746 - acc: 0.8484 - val_loss: 0.4304 - val_acc: 0.8157\n",
            "Epoch 20/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3714 - acc: 0.8480 - val_loss: 0.4082 - val_acc: 0.8413\n",
            "Epoch 21/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.3723 - acc: 0.8490 - val_loss: 0.4369 - val_acc: 0.8191\n",
            "Epoch 22/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3617 - acc: 0.8539 - val_loss: 0.4658 - val_acc: 0.8448\n",
            "Epoch 23/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.3634 - acc: 0.8522 - val_loss: 0.3615 - val_acc: 0.8588\n",
            "Epoch 24/75\n",
            "263/263 [==============================] - 25s 96ms/step - loss: 0.3626 - acc: 0.8536 - val_loss: 0.3575 - val_acc: 0.8618\n",
            "Epoch 25/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.3496 - acc: 0.8597 - val_loss: 0.3750 - val_acc: 0.8546\n",
            "Epoch 26/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3534 - acc: 0.8582 - val_loss: 0.5019 - val_acc: 0.8000\n",
            "Epoch 27/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.3522 - acc: 0.8587 - val_loss: 0.4002 - val_acc: 0.8365\n",
            "Epoch 28/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3478 - acc: 0.8607 - val_loss: 0.4194 - val_acc: 0.8380\n",
            "Epoch 29/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3461 - acc: 0.8617 - val_loss: 0.3519 - val_acc: 0.8617\n",
            "Epoch 30/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3402 - acc: 0.8644 - val_loss: 0.3418 - val_acc: 0.8630\n",
            "Epoch 31/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3389 - acc: 0.8656 - val_loss: 0.3956 - val_acc: 0.8552\n",
            "Epoch 32/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3396 - acc: 0.8635 - val_loss: 0.3640 - val_acc: 0.8517\n",
            "Epoch 33/75\n",
            "263/263 [==============================] - 24s 93ms/step - loss: 0.3338 - acc: 0.8672 - val_loss: 0.3800 - val_acc: 0.8580\n",
            "Epoch 34/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3291 - acc: 0.8688 - val_loss: 0.3687 - val_acc: 0.8564\n",
            "Epoch 35/75\n",
            "263/263 [==============================] - 24s 93ms/step - loss: 0.3290 - acc: 0.8686 - val_loss: 0.4033 - val_acc: 0.8538\n",
            "Epoch 36/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3281 - acc: 0.8695 - val_loss: 0.3344 - val_acc: 0.8664\n",
            "Epoch 37/75\n",
            "263/263 [==============================] - 25s 97ms/step - loss: 0.3254 - acc: 0.8688 - val_loss: 0.3901 - val_acc: 0.8531\n",
            "Epoch 38/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3295 - acc: 0.8668 - val_loss: 0.3589 - val_acc: 0.8675\n",
            "Epoch 39/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3234 - acc: 0.8706 - val_loss: 0.3649 - val_acc: 0.8660\n",
            "Epoch 40/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3238 - acc: 0.8714 - val_loss: 0.3237 - val_acc: 0.8704\n",
            "Epoch 41/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3203 - acc: 0.8721 - val_loss: 0.3423 - val_acc: 0.8646\n",
            "Epoch 42/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3170 - acc: 0.8729 - val_loss: 0.3981 - val_acc: 0.8331\n",
            "Epoch 43/75\n",
            "263/263 [==============================] - 25s 94ms/step - loss: 0.3234 - acc: 0.8705 - val_loss: 0.3277 - val_acc: 0.8726\n",
            "Epoch 44/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3160 - acc: 0.8741 - val_loss: 0.3777 - val_acc: 0.8542\n",
            "Epoch 45/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3164 - acc: 0.8723 - val_loss: 0.3366 - val_acc: 0.8637\n",
            "Epoch 46/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.3129 - acc: 0.8743 - val_loss: 0.3311 - val_acc: 0.8728\n",
            "Epoch 47/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3143 - acc: 0.8746 - val_loss: 0.3415 - val_acc: 0.8700\n",
            "Epoch 48/75\n",
            "263/263 [==============================] - 24s 93ms/step - loss: 0.3260 - acc: 0.8691 - val_loss: 0.3477 - val_acc: 0.8696\n",
            "Epoch 49/75\n",
            "263/263 [==============================] - 24s 93ms/step - loss: 0.3101 - acc: 0.8747 - val_loss: 0.3262 - val_acc: 0.8699\n",
            "Epoch 50/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3117 - acc: 0.8743 - val_loss: 0.3341 - val_acc: 0.8660\n",
            "Epoch 51/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.3075 - acc: 0.8759 - val_loss: 0.6723 - val_acc: 0.8270\n",
            "Epoch 52/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.3059 - acc: 0.8760 - val_loss: 0.3181 - val_acc: 0.8754\n",
            "Epoch 53/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.3088 - acc: 0.8756 - val_loss: 0.3228 - val_acc: 0.8742\n",
            "Epoch 54/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.3045 - acc: 0.8782 - val_loss: 0.3282 - val_acc: 0.8737\n",
            "Epoch 55/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.3027 - acc: 0.8800 - val_loss: 0.3494 - val_acc: 0.8652\n",
            "Epoch 56/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3304 - acc: 0.8659 - val_loss: 0.3607 - val_acc: 0.8605\n",
            "Epoch 57/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.3138 - acc: 0.8725 - val_loss: 0.3241 - val_acc: 0.8715\n",
            "Epoch 58/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.3079 - acc: 0.8760 - val_loss: 0.3211 - val_acc: 0.8736\n",
            "Epoch 59/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.3032 - acc: 0.8786 - val_loss: 0.3301 - val_acc: 0.8710\n",
            "Epoch 60/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2975 - acc: 0.8807 - val_loss: 0.3498 - val_acc: 0.8574\n",
            "Epoch 61/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2997 - acc: 0.8790 - val_loss: 0.3207 - val_acc: 0.8759\n",
            "Epoch 62/75\n",
            "263/263 [==============================] - 24s 93ms/step - loss: 0.2941 - acc: 0.8809 - val_loss: 0.3140 - val_acc: 0.8796\n",
            "Epoch 63/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.3043 - acc: 0.8767 - val_loss: 0.3406 - val_acc: 0.8667\n",
            "Epoch 64/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2946 - acc: 0.8810 - val_loss: 0.3644 - val_acc: 0.8530\n",
            "Epoch 65/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.2953 - acc: 0.8796 - val_loss: 0.3741 - val_acc: 0.8622\n",
            "Epoch 66/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.2930 - acc: 0.8807 - val_loss: 0.3568 - val_acc: 0.8710\n",
            "Epoch 67/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.2920 - acc: 0.8818 - val_loss: 0.3419 - val_acc: 0.8676\n",
            "Epoch 68/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2951 - acc: 0.8794 - val_loss: 0.3185 - val_acc: 0.8748\n",
            "Epoch 69/75\n",
            "263/263 [==============================] - 25s 93ms/step - loss: 0.2880 - acc: 0.8836 - val_loss: 0.3207 - val_acc: 0.8736\n",
            "Epoch 70/75\n",
            "263/263 [==============================] - 24s 90ms/step - loss: 0.2960 - acc: 0.8794 - val_loss: 0.3116 - val_acc: 0.8754\n",
            "Epoch 71/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2948 - acc: 0.8804 - val_loss: 0.3256 - val_acc: 0.8763\n",
            "Epoch 72/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2897 - acc: 0.8827 - val_loss: 0.3171 - val_acc: 0.8807\n",
            "Epoch 73/75\n",
            "263/263 [==============================] - 24s 92ms/step - loss: 0.2864 - acc: 0.8837 - val_loss: 0.3331 - val_acc: 0.8714\n",
            "Epoch 74/75\n",
            "263/263 [==============================] - 24s 91ms/step - loss: 0.2868 - acc: 0.8853 - val_loss: 0.3625 - val_acc: 0.8512\n",
            "Epoch 75/75\n",
            "263/263 [==============================] - 25s 95ms/step - loss: 0.2873 - acc: 0.8826 - val_loss: 0.3327 - val_acc: 0.8686\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X5mBdx0aab4t",
        "colab_type": "code",
        "outputId": "54a1745e-0911-4d82-f572-b8aa43555bdb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# save the model to disk\n",
        "print(\"[INFO] serializing network...\")\n",
        "model.save(output_model_path)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] serializing network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HAm5MLmpU1Ov",
        "colab_type": "code",
        "outputId": "2002cb6a-0803-44e6-d2d4-f024aa756aca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# save the multi-label binarizer to disk\n",
        "print(\"[INFO] serializing label binarizer...\")\n",
        "f = open(labelbin, \"wb\")\n",
        "f.write(pickle.dumps(mlb))\n",
        "f.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] serializing label binarizer...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tWtPB5nJZSvp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot the training loss and accuracy\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "N = EPOCHS\n",
        "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, N), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, N), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.savefig(plot)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vw_KK5iej-Oy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#img_path = \"/content/example_05.jpg\"\n",
        "img_path = \"/content/testimg.jpg\"\n",
        "image = cv2.imread(img_path)\n",
        "output = imutils.resize(image, width=400)\n",
        " "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otFhQW5uU20l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "po2xduPFU6O0",
        "colab_type": "code",
        "outputId": "542a077f-e037-4474-9c39-2a14a113ce2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "#plt.imshow(np.array(output))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fa330954ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "c6KIZnD9O7UI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pre-process the image for classification\n",
        "image = cv2.resize(image, (96, 96))\n",
        "image = image.astype(\"float\") / 255.0\n",
        "image = img_to_array(image)\n",
        "image = np.expand_dims(image, axis=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oyQnGHnXPCOO",
        "colab_type": "code",
        "outputId": "e96132c0-1d34-4c62-e033-1b48719d990b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] loading network...\")\n",
        "model_ = \"/content/ssteel.model\"\n",
        "model = load_model(model_)\n",
        "labelbin_ = \"/content/steel_mlb.pickle\"\n",
        "mlb = pickle.loads(open(labelbin_, \"rb\").read())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading network...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nT7sIF8pPM7q",
        "colab_type": "code",
        "outputId": "7695cbfa-6399-439b-98df-0d2bc5d3818e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "# classify the input image then find the indexes of the two class\n",
        "# labels with the *largest* probability\n",
        "print(\"[INFO] classifying image...\")\n",
        "proba = model.predict(image)[0]\n",
        "idxs = np.argsort(proba)[::-1][:2]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] classifying image...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hDK9QKUkPP2X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# loop over the indexes of the high confidence class labels\n",
        "for (i, j) in enumerate(idxs):\n",
        "\t# build the label and draw the label on the image\n",
        "\tlabel = \"{}: {:.2f}%\".format(mlb.classes_[j], proba[j] * 100)\n",
        "\tcv2.putText(output, label, (10, (i * 30) + 25), \n",
        "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EKTLFmxaNNhZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "stainless_steel_Chimney: 78.78%\n",
        "stainless_steel_Dishwasher: 1.25%\n",
        "stainless_steel_Microwave: 5.17%\n",
        "stainless_steel_Sink: 30.96%\n",
        "stainless_steel_Stove: 47.70%\n",
        "stainless_steel_fridge: 90.79%\n",
        "stainless_steel_oven: 22.22%"
      ]
    },
    {
      "metadata": {
        "id": "Ipp5emchPSgw",
        "colab_type": "code",
        "outputId": "df08123d-96b1-4db2-c214-9031556b08c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "cell_type": "code",
      "source": [
        "# show the probabilities for each of the individual labels\n",
        "for (label, p) in zip(mlb.classes_, proba):\n",
        "\tprint(\"{}: {:.2f}%\".format(label, p * 100))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "stainless_steel_Chimney: 7.61%\n",
            "stainless_steel_Dishwasher: 23.71%\n",
            "stainless_steel_Microwave: 30.70%\n",
            "stainless_steel_Sink: 19.92%\n",
            "stainless_steel_Stove: 9.61%\n",
            "stainless_steel_fridge: 18.70%\n",
            "stainless_steel_oven: 36.97%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WdLFqERMPW76",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# show the output image\n",
        "# cv2.imshow(\"Output\", output)\n",
        "# cv2.waitKey(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Be0pt-8lUtMy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Lets train Inception v3"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C872vIHcX865",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras import backend as K\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.layers import *\n",
        "from keras.models import Model\n",
        "from keras.models import load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yQONtQy9YG_K",
        "colab_type": "code",
        "outputId": "2d9edd29-db0d-4cf4-a99b-eb3105f06f59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "base_model = InceptionV3(weights='imagenet', include_top=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 3s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tFq-fwnMYNFZ",
        "colab_type": "code",
        "outputId": "73825272-7fa2-407e-8182-9a1a4a90bcd1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "cell_type": "code",
      "source": [
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.3)(x)\n",
        "# let's add a fully-connected layer\n",
        "x = Dense(1024, activation='relu')(x)\n",
        "x = Dropout(0.3)(x)\n",
        "predictions = Dense(7, activation='sigmoid')(x)\n",
        "\n",
        " # this is the model we will train\n",
        "model = Model(input=base_model.input, output=predictions)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "zpq-pQTxY6hC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "spMMoH5vZGJi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rjye2GXG1red",
        "colab_type": "code",
        "outputId": "9b67a56b-11f4-4dc4-9cbc-bd5631d58133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 12272
        }
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, None, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, None, None, 3 864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, None, None, 3 96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, None, None, 3 0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, None, None, 3 9216        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, None, None, 3 96          conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, None, None, 3 0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, None, None, 6 18432       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, None, None, 6 192         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, None, None, 6 0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, None, None, 6 0           activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, None, None, 8 5120        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, None, None, 8 240         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, None, None, 8 0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, None, None, 1 138240      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, None, None, 1 576         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, None, None, 1 0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, None, None, 1 0           activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, None, None, 6 192         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, None, None, 6 0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, None, None, 4 9216        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, None, None, 9 55296       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, None, None, 4 144         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, None, None, 9 288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, None, None, 4 0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, None, None, 9 0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, None, None, 1 0           max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, None, None, 6 12288       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, None, None, 6 76800       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, None, None, 9 82944       activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, None, None, 3 6144        average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, None, None, 6 192         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, None, None, 6 192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, None, None, 9 288         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, None, None, 3 96          conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, None, None, 6 0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, None, None, 6 0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, None, None, 9 0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, None, None, 3 0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, None, None, 2 0           activation_6[0][0]               \n",
            "                                                                 activation_8[0][0]               \n",
            "                                                                 activation_11[0][0]              \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, None, None, 6 192         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, None, None, 6 0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, None, None, 4 12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, None, None, 9 55296       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, None, None, 4 144         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, None, None, 9 288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, None, None, 4 0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, None, None, 9 0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, None, None, 2 0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, None, None, 6 16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, None, None, 6 76800       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, None, None, 9 82944       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, None, None, 6 16384       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, None, None, 6 192         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, None, None, 6 192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, None, None, 9 288         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, None, None, 6 192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, None, None, 6 0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, None, None, 6 0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, None, None, 9 0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, None, None, 6 0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, None, None, 2 0           activation_13[0][0]              \n",
            "                                                                 activation_15[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "                                                                 activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, None, None, 6 192         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, None, None, 6 0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, None, None, 4 13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, None, None, 9 55296       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, None, None, 4 144         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, None, None, 9 288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, None, None, 4 0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, None, None, 9 0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, None, None, 2 0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, None, None, 6 18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, None, None, 6 76800       activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, None, None, 9 82944       activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, None, None, 6 18432       average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, None, None, 6 192         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, None, None, 6 192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, None, None, 9 288         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, None, None, 6 192         conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, None, None, 6 0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, None, None, 6 0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, None, None, 9 0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, None, None, 6 0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, None, None, 2 0           activation_20[0][0]              \n",
            "                                                                 activation_22[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "                                                                 activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, None, None, 6 18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, None, None, 6 192         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, None, None, 6 0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, None, None, 9 55296       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, None, None, 9 288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, None, None, 9 0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, None, None, 3 995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, None, None, 9 82944       activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, None, None, 3 1152        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, None, None, 9 288         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, None, None, 3 0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, None, None, 9 0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, None, None, 2 0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, None, None, 7 0           activation_27[0][0]              \n",
            "                                                                 activation_30[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, None, None, 1 384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, None, None, 1 0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, None, None, 1 114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, None, None, 1 384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, None, None, 1 0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, None, None, 1 98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, None, None, 1 114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, None, None, 1 384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, None, None, 1 384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, None, None, 1 0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, None, None, 1 0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, None, None, 1 114688      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, None, None, 1 114688      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, None, None, 1 384         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, None, None, 1 384         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, None, None, 1 0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, None, None, 1 0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, None, None, 7 0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, None, None, 1 147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, None, None, 1 172032      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, None, None, 1 172032      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, None, None, 1 576         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, None, None, 1 576         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, None, None, 1 576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, None, None, 1 576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, None, None, 1 0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, None, None, 1 0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, None, None, 1 0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, None, None, 1 0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, None, None, 7 0           activation_31[0][0]              \n",
            "                                                                 activation_34[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "                                                                 activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, None, None, 1 480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, None, None, 1 0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, None, None, 1 179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, None, None, 1 480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, None, None, 1 0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, None, None, 1 122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, None, None, 1 179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, None, None, 1 480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, None, None, 1 480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, None, None, 1 0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, None, None, 1 0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, None, None, 1 179200      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, None, None, 1 179200      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, None, None, 1 480         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, None, None, 1 480         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, None, None, 1 0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, None, None, 1 0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, None, None, 7 0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, None, None, 1 147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, None, None, 1 215040      activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, None, None, 1 215040      activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, None, None, 1 576         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, None, None, 1 576         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, None, None, 1 576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, None, None, 1 576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, None, None, 1 0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, None, None, 1 0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, None, None, 1 0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, None, None, 1 0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, None, None, 7 0           activation_41[0][0]              \n",
            "                                                                 activation_44[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "                                                                 activation_50[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, None, None, 1 480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, None, None, 1 0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, None, None, 1 179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, None, None, 1 480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, None, None, 1 0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, None, None, 1 122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, None, None, 1 179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, None, None, 1 480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, None, None, 1 480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, None, None, 1 0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, None, None, 1 0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, None, None, 1 179200      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, None, None, 1 179200      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, None, None, 1 480         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, None, None, 1 480         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, None, None, 1 0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, None, None, 1 0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, None, None, 7 0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, None, None, 1 147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, None, None, 1 215040      activation_53[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, None, None, 1 215040      activation_58[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, None, None, 1 576         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, None, None, 1 576         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, None, None, 1 576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, None, None, 1 576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, None, None, 1 0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, None, None, 1 0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, None, None, 1 0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, None, None, 1 0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, None, None, 7 0           activation_51[0][0]              \n",
            "                                                                 activation_54[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "                                                                 activation_60[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, None, None, 1 576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, None, None, 1 0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, None, None, 1 258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, None, None, 1 576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, None, None, 1 0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, None, None, 1 258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, None, None, 1 576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, None, None, 1 576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, None, None, 1 0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, None, None, 1 0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, None, None, 1 258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, None, None, 1 258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, None, None, 1 576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, None, None, 1 576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, None, None, 1 0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, None, None, 1 0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, None, None, 7 0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, None, None, 1 147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, None, None, 1 258048      activation_63[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, None, None, 1 258048      activation_68[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, None, None, 1 147456      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, None, None, 1 576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, None, None, 1 576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, None, None, 1 576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, None, None, 1 576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, None, None, 1 0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, None, None, 1 0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, None, None, 1 0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, None, None, 1 0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, None, None, 7 0           activation_61[0][0]              \n",
            "                                                                 activation_64[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "                                                                 activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, None, None, 1 576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, None, None, 1 0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, None, None, 1 258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, None, None, 1 576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, None, None, 1 0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, None, None, 1 147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, None, None, 1 258048      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, None, None, 1 576         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, None, None, 1 576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, None, None, 1 0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, None, None, 1 0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, None, None, 3 552960      activation_71[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, None, None, 1 331776      activation_75[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, None, None, 3 960         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, None, None, 1 576         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, None, None, 3 0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, None, None, 1 0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, None, None, 7 0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, None, None, 1 0           activation_72[0][0]              \n",
            "                                                                 activation_76[0][0]              \n",
            "                                                                 max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, None, None, 4 573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, None, None, 4 1344        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, None, None, 4 0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, None, None, 3 491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, None, None, 3 1548288     activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, None, None, 3 1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, None, None, 3 1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, None, None, 3 0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, None, None, 3 0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, None, None, 3 442368      activation_78[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, None, None, 3 442368      activation_82[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, None, None, 1 0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, None, None, 3 409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, None, None, 3 1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, None, None, 3 1152        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, None, None, 3 1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, None, None, 3 1152        conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, None, None, 1 245760      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, None, None, 3 960         conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, None, None, 3 0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, None, None, 3 0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, None, None, 3 0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, None, None, 3 0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, None, None, 1 576         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, None, None, 3 0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, None, None, 7 0           activation_79[0][0]              \n",
            "                                                                 activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, None, 7 0           activation_83[0][0]              \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, None, None, 1 0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, None, None, 2 0           activation_77[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_85[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, None, None, 4 917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, None, None, 4 1344        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, None, None, 4 0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, None, None, 3 786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, None, None, 3 1548288     activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, None, None, 3 1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, None, None, 3 1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, None, None, 3 0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, None, None, 3 0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, None, None, 3 442368      activation_87[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, None, None, 3 442368      activation_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_9 (AveragePoo (None, None, None, 2 0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, None, None, 3 655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, None, None, 3 1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, None, None, 3 1152        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, None, None, 3 1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, None, None, 3 1152        conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_94 (Conv2D)              (None, None, None, 1 393216      average_pooling2d_9[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, None, None, 3 960         conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, None, None, 3 0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, None, None, 3 0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, None, None, 3 0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, None, None, 3 0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_94 (BatchNo (None, None, None, 1 576         conv2d_94[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, None, None, 3 0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, None, None, 7 0           activation_88[0][0]              \n",
            "                                                                 activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, None, 7 0           activation_92[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_94 (Activation)      (None, None, None, 1 0           batch_normalization_94[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, None, None, 2 0           activation_86[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_2[0][0]              \n",
            "                                                                 activation_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "global_average_pooling2d_1 (Glo (None, 2048)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 1024)         2098176     dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 7)            7175        dropout_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 23,908,135\n",
            "Trainable params: 2,105,351\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8dDtaaRkQaJ1",
        "colab_type": "code",
        "outputId": "e5fabc0e-c742-4fdf-bcde-14b3a301629c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "len(trainX), len(testX),len(trainY), len(testY)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2400, 600, 2400, 600)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "oeQad1ZpCjmn",
        "colab_type": "code",
        "outputId": "2d69114e-172a-4515-be51-5c5e13c61ad0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trainX.shape, testX.shape, trainY.shape, testY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2400, 256, 256, 3), (600, 256, 256, 3), (2400, 7), (600, 7))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "dZxqr2vkC7JS",
        "colab_type": "code",
        "outputId": "c500ec82-d402-4cb1-da67-b332558c4477",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "trainY[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 0, 0, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "metadata": {
        "id": "GW_dWG3SZOAI",
        "colab_type": "code",
        "outputId": "fed41fc4-4f91-430b-a0db-95f7a3c5c0ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"[INFO] training network...\")\n",
        "H = model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size= BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=250, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training network...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7b65613ffa58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"[INFO] training network...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m H = model.fit_generator(\n\u001b[0m\u001b[1;32m      3\u001b[0m         \u001b[0maug\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mBS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "IY2-9BNXCh_X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Vt8d6Cn41-uB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
        "# the first 172 layers and unfreeze the rest:\n",
        "for layer in model.layers[:172]:\n",
        "  layer.trainable = False\n",
        "for layer in model.layers[172:]:\n",
        "  layer.trainable = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "g-1bmm9I6fm_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.optimizers import SGD\n",
        "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9),loss='binary_crossentropy',metrics=[\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ri0FM_su6uTn",
        "colab_type": "code",
        "outputId": "6825d7cb-5770-4536-d688-12530ccb79a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2745
        }
      },
      "cell_type": "code",
      "source": [
        "H = model.fit_generator(\n",
        "\taug.flow(trainX, trainY, batch_size=BS),\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tsteps_per_epoch=len(trainX) // BS,\n",
        "\tepochs=EPOCHS, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/75\n",
            "263/263 [==============================] - 45s 173ms/step - loss: 0.4401 - acc: 0.8213 - val_loss: 0.4508 - val_acc: 0.8169\n",
            "Epoch 2/75\n",
            "263/263 [==============================] - 38s 143ms/step - loss: 0.4395 - acc: 0.8213 - val_loss: 0.4505 - val_acc: 0.8169\n",
            "Epoch 3/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4396 - acc: 0.8216 - val_loss: 0.4501 - val_acc: 0.8169\n",
            "Epoch 4/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4388 - acc: 0.8216 - val_loss: 0.4505 - val_acc: 0.8169\n",
            "Epoch 5/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4398 - acc: 0.8214 - val_loss: 0.4501 - val_acc: 0.8170\n",
            "Epoch 6/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4377 - acc: 0.8217 - val_loss: 0.4501 - val_acc: 0.8170\n",
            "Epoch 7/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4403 - acc: 0.8200 - val_loss: 0.4509 - val_acc: 0.8170\n",
            "Epoch 8/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4390 - acc: 0.8215 - val_loss: 0.4504 - val_acc: 0.8169\n",
            "Epoch 9/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4377 - acc: 0.8222 - val_loss: 0.4506 - val_acc: 0.8170\n",
            "Epoch 10/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4380 - acc: 0.8206 - val_loss: 0.4507 - val_acc: 0.8170\n",
            "Epoch 11/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4385 - acc: 0.8205 - val_loss: 0.4510 - val_acc: 0.8170\n",
            "Epoch 12/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4371 - acc: 0.8223 - val_loss: 0.4509 - val_acc: 0.8169\n",
            "Epoch 13/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4365 - acc: 0.8218 - val_loss: 0.4508 - val_acc: 0.8169\n",
            "Epoch 14/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4379 - acc: 0.8208 - val_loss: 0.4509 - val_acc: 0.8169\n",
            "Epoch 15/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4383 - acc: 0.8215 - val_loss: 0.4508 - val_acc: 0.8169\n",
            "Epoch 16/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4372 - acc: 0.8220 - val_loss: 0.4512 - val_acc: 0.8169\n",
            "Epoch 17/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4401 - acc: 0.8198 - val_loss: 0.4509 - val_acc: 0.8169\n",
            "Epoch 18/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4362 - acc: 0.8225 - val_loss: 0.4508 - val_acc: 0.8169\n",
            "Epoch 19/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4378 - acc: 0.8211 - val_loss: 0.4503 - val_acc: 0.8169\n",
            "Epoch 20/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4364 - acc: 0.8217 - val_loss: 0.4502 - val_acc: 0.8169\n",
            "Epoch 21/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4371 - acc: 0.8214 - val_loss: 0.4509 - val_acc: 0.8169\n",
            "Epoch 22/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4385 - acc: 0.8211 - val_loss: 0.4516 - val_acc: 0.8170\n",
            "Epoch 23/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4366 - acc: 0.8215 - val_loss: 0.4515 - val_acc: 0.8169\n",
            "Epoch 24/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4358 - acc: 0.8221 - val_loss: 0.4518 - val_acc: 0.8169\n",
            "Epoch 25/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4360 - acc: 0.8212 - val_loss: 0.4514 - val_acc: 0.8170\n",
            "Epoch 26/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4341 - acc: 0.8228 - val_loss: 0.4520 - val_acc: 0.8170\n",
            "Epoch 27/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4372 - acc: 0.8206 - val_loss: 0.4521 - val_acc: 0.8170\n",
            "Epoch 28/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4342 - acc: 0.8217 - val_loss: 0.4521 - val_acc: 0.8170\n",
            "Epoch 29/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4382 - acc: 0.8201 - val_loss: 0.4520 - val_acc: 0.8170\n",
            "Epoch 30/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4356 - acc: 0.8214 - val_loss: 0.4521 - val_acc: 0.8170\n",
            "Epoch 31/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4330 - acc: 0.8228 - val_loss: 0.4521 - val_acc: 0.8170\n",
            "Epoch 32/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4344 - acc: 0.8212 - val_loss: 0.4523 - val_acc: 0.8170\n",
            "Epoch 33/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4371 - acc: 0.8206 - val_loss: 0.4526 - val_acc: 0.8170\n",
            "Epoch 34/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4358 - acc: 0.8217 - val_loss: 0.4523 - val_acc: 0.8170\n",
            "Epoch 35/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4354 - acc: 0.8209 - val_loss: 0.4515 - val_acc: 0.8170\n",
            "Epoch 36/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4342 - acc: 0.8216 - val_loss: 0.4521 - val_acc: 0.8170\n",
            "Epoch 37/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4329 - acc: 0.8224 - val_loss: 0.4517 - val_acc: 0.8170\n",
            "Epoch 38/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4350 - acc: 0.8207 - val_loss: 0.4519 - val_acc: 0.8170\n",
            "Epoch 39/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4341 - acc: 0.8216 - val_loss: 0.4509 - val_acc: 0.8169\n",
            "Epoch 40/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4324 - acc: 0.8225 - val_loss: 0.4513 - val_acc: 0.8169\n",
            "Epoch 41/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4355 - acc: 0.8203 - val_loss: 0.4515 - val_acc: 0.8168\n",
            "Epoch 42/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4339 - acc: 0.8221 - val_loss: 0.4516 - val_acc: 0.8169\n",
            "Epoch 43/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4300 - acc: 0.8235 - val_loss: 0.4520 - val_acc: 0.8169\n",
            "Epoch 44/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4361 - acc: 0.8199 - val_loss: 0.4523 - val_acc: 0.8169\n",
            "Epoch 45/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4332 - acc: 0.8221 - val_loss: 0.4522 - val_acc: 0.8168\n",
            "Epoch 46/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4333 - acc: 0.8223 - val_loss: 0.4516 - val_acc: 0.8168\n",
            "Epoch 47/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4343 - acc: 0.8199 - val_loss: 0.4513 - val_acc: 0.8168\n",
            "Epoch 48/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4314 - acc: 0.8224 - val_loss: 0.4516 - val_acc: 0.8168\n",
            "Epoch 49/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4324 - acc: 0.8223 - val_loss: 0.4522 - val_acc: 0.8169\n",
            "Epoch 50/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4326 - acc: 0.8218 - val_loss: 0.4511 - val_acc: 0.8168\n",
            "Epoch 51/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4323 - acc: 0.8212 - val_loss: 0.4511 - val_acc: 0.8168\n",
            "Epoch 52/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4332 - acc: 0.8213 - val_loss: 0.4511 - val_acc: 0.8168\n",
            "Epoch 53/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4327 - acc: 0.8209 - val_loss: 0.4517 - val_acc: 0.8169\n",
            "Epoch 54/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4295 - acc: 0.8228 - val_loss: 0.4518 - val_acc: 0.8168\n",
            "Epoch 55/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4335 - acc: 0.8204 - val_loss: 0.4520 - val_acc: 0.8168\n",
            "Epoch 56/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4292 - acc: 0.8226 - val_loss: 0.4519 - val_acc: 0.8167\n",
            "Epoch 57/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4339 - acc: 0.8211 - val_loss: 0.4514 - val_acc: 0.8169\n",
            "Epoch 58/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4298 - acc: 0.8227 - val_loss: 0.4517 - val_acc: 0.8168\n",
            "Epoch 59/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4304 - acc: 0.8215 - val_loss: 0.4517 - val_acc: 0.8167\n",
            "Epoch 60/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4301 - acc: 0.8222 - val_loss: 0.4516 - val_acc: 0.8166\n",
            "Epoch 61/75\n",
            "263/263 [==============================] - 37s 142ms/step - loss: 0.4334 - acc: 0.8195 - val_loss: 0.4518 - val_acc: 0.8170\n",
            "Epoch 62/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4279 - acc: 0.8237 - val_loss: 0.4520 - val_acc: 0.8169\n",
            "Epoch 63/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4298 - acc: 0.8220 - val_loss: 0.4520 - val_acc: 0.8171\n",
            "Epoch 64/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4327 - acc: 0.8197 - val_loss: 0.4520 - val_acc: 0.8170\n",
            "Epoch 65/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4274 - acc: 0.8236 - val_loss: 0.4520 - val_acc: 0.8168\n",
            "Epoch 66/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4286 - acc: 0.8229 - val_loss: 0.4524 - val_acc: 0.8170\n",
            "Epoch 67/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4293 - acc: 0.8220 - val_loss: 0.4521 - val_acc: 0.8168\n",
            "Epoch 68/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4287 - acc: 0.8217 - val_loss: 0.4524 - val_acc: 0.8167\n",
            "Epoch 69/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4308 - acc: 0.8210 - val_loss: 0.4515 - val_acc: 0.8169\n",
            "Epoch 70/75\n",
            "263/263 [==============================] - 37s 143ms/step - loss: 0.4327 - acc: 0.8196 - val_loss: 0.4503 - val_acc: 0.8171\n",
            "Epoch 71/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4260 - acc: 0.8247 - val_loss: 0.4509 - val_acc: 0.8172\n",
            "Epoch 72/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4291 - acc: 0.8208 - val_loss: 0.4513 - val_acc: 0.8171\n",
            "Epoch 73/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4287 - acc: 0.8229 - val_loss: 0.4513 - val_acc: 0.8170\n",
            "Epoch 74/75\n",
            "263/263 [==============================] - 37s 141ms/step - loss: 0.4316 - acc: 0.8201 - val_loss: 0.4510 - val_acc: 0.8170\n",
            "Epoch 75/75\n",
            "263/263 [==============================] - 37s 140ms/step - loss: 0.4278 - acc: 0.8225 - val_loss: 0.4508 - val_acc: 0.8172\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5LKq89XC7IZa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}